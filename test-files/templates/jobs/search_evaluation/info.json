{
  "jobName": "Name of the job. If job with same name is already running, the job request will be denied.",
  "requestTasks": "Number of execution tasks requested. A task corresponds to a single batch.",
  "fixedParams": "Mapping of parameter name to a list of values. The lists can contain a single or multiple values. The latter is useful when one parameter can have multiple values, e.g p=a&p=b&p=c",
  "contextPath": "The context path of the requests",
  "connections": "List of connections, where each connection is represented by value for keys: host, port, useHttps and optional credentials.",
  "requestPermutation": "Specifies the permutations of modifications made to the base request (executed on a connection, using the defined context path). Modifications can either be parameters, bodies or headers. The order in which those are defined is relevant for the batchByIndex setting.",
  "batchByIndex": "The index of the permutation to batch the overall permutations by. The index corresponds directly to the order or permutations defined in the requestPermutation setting.",
  "parsingConfig": "Describes json selectors describing the data to extract from the responses of the requests along with a castType and the name under which this is to be placed in the result map, based on which further computations can be defined in the following definitions.",
  "excludeParamsFromMetricRow": "A result for a single parameter setting corresponds to a MetricRow. On aggregation of single results, MetricRows corresponding to the same parameters are aggregated. Thus this setting serves to exclude fixed parameters and irrelevant parameters from the MetricRow result. E.g in case you group by query, and want to aggregate over multiple queries, make sure to exclude the query parameter from MetricRow by including it in this list.",
  "taggingConfiguration": "This setting allows you to define how your single results shall be tagged. As of now there are three types of taggers, the initTagger working on the initial request, where you can tag by properties of the initial request (e.g url parameters). The processedTagger allows you to tag based on the properties of the parsed result and the resultTagger allows tagging based on properties of the resulting MetricRow",
  "requestTemplateStorageKey": "Setting just defines under which key in the weakly typed map that represents the result the initial request template is stored. Not relevant for anything else than to avoid key clashes, e.g you can leave it at requestTemplate if youre not parsing any info out of the result that has the same key.",
  "mapFutureMetricRowCalculation": "Defines IR metrics to be calculated on the result besides details such as which result key (referring to the key of the parsed result defined above) to use to extract the productIds, which judgement provider to use, the MetricsCalculation itself (e.g which metrics to calculate and how to handle missing judgements, and what validations to execute on the judgements (e.g whether there are any search results, whether there are any judgements,...)",
  "singleMapCalculations": "Definition of additional metrics to calculate based on any extracted field referenced by name as defined in the parsingConfig",
  "allowedTimePerElementInMillis": "Time limit (in millis) for a single element to be processed (e.g single evaluation)",
  "allowedTimePerBatchInSeconds": "Time limit (in seconds) for a whole batch to be executed",
  "allowedTimeForJobInSeconds": "Time limit (in seconds) for a whole job to be executed",
  "expectResultsFromBatchCalculations": "Boolean indicating whether the JobManager results corresponding to the single batches back from the single workers. If set to false, not the full result is sent back but just a confirmation that the execution was finished. Recommended to leave this as false, as it works better storing the results from single worker, and later execute the aggregations needed. There might be incomplete data due to serialization issue in case the single result is big if this is set to true",
  "wrapUpFunction": "(Optional) Here you can define a wrapUpFunction that will be executed on the JobManager node after the job is completed. One use case is to aggregate all partial results to an overall aggregation."
}