kolibri {
  actor-system = "KolibriApp"
  request {
    parallelism = 32
    useTracking = false
    useConnectionPoolFlow = false
    connection.pool.mode = "STANDARD"
    connection.pool.mode = ${?CONNECTION_POOL_MODE}
    connection.pool.moduleClass = ""
    connection.pool.moduleClass = ${?CONNECTION_POOL_MODULE_CLASS}
  }
  job {
   timeoutInSeconds = 1800
   processingCheckResourcesIntervalInMillis = 100
   runningTasksPerJobMaxCount = 5
   runningTasksPerJobDefaultCount = 2
   batchDistributionIntervalInMs = 1000
   batchMaxTimeToACKInMs = 1000
   resources {
   }
   tasks {
     waitForSynchronousTaskCompleteInMs = 100
   }
  }
  cluster {
    statusCheckTimeoutInMillis = 1000
    startClusterSingletonRouter = false
  }
  supervisor {
    maxNumOfRetries = 3
    maxNumOfRetriesWithinTimeInSeconds = 60
    houseKeepingIntervalInSeconds = 10
  }
  execution {
    runnableExecutionHouseKeepingIntervalInSeconds = 10
    jobManagerCheckForCompletionIntervalInSeconds = 5
    useAggregatorBackpressure = true
    aggregatorResultReceiveParallelism = 200
    useResultElementGrouping = true
    resultElementGroupingCount = 500
    resultElementGroupingIntervalInMs = 500
    resultElementGroupingParallelism = 1
    maxNrBatchRetries = 2
  }
  format {
    metricDocumentFormatType = "parameter"
    judgements {
      sourceType = "CSV"
      judgementKeyQueryAndProductDelimiter = "\u0000"
      jsonLines {
        queryPath = "query"
        queryPath = ${?JUDGEMENT_FILE_JSON_LINES_QUERY_PATH}
        productsPath = "products"
        productsPath = ${?JUDGEMENT_FILE_JSON_LINES_PRODUCTS_PATH}
        productIdSelector = "productId"
        productIdSelector = ${?JUDGEMENT_FILE_JSON_LINES_PRODUCT_ID_SELECTOR}
        judgementSelector = "score"
        judgementSelector = ${?JUDGEMENT_FILE_JSON_LINES_JUDGEMENT_SELECTOR}
        judgementValueTypeCast = "DOUBLE"
        judgementValueTypeCast = ${?JUDGEMENT_FILE_JSON_LINES_JUDGEMENT_VALUE_TYPE_CAST}
      }
      csv {
        judgementFileColumnDelimiter = "\u0000"
        judgementFileColumnDelimiter = ${?JUDGEMENT_FILE_COLUMN_DELIMITER}
        judgementFileIgnoreLessThanColumns = 3
        judgementFileIgnoreLessThanColumns = ${?JUDGEMENT_FILE_IGNORE_LESS_THAN_COLUMNS}
        judgementFileJudgementColumn = 2
        judgementFileJudgementColumn = ${?JUDGEMENT_FILE_JUDGEMENT_COLUMN}
        judgementFileSearchTermColumn = 0,
        judgementFileSearchTermColumn = ${?JUDGEMENT_FILE_SEARCH_TERM_COLUMN}
        judgementFileProductIdColumn = 1
        judgementFileProductIdColumn = ${?JUDGEMENT_FILE_PRODUCT_ID_COLUMN}
      }
    }
  }
  persistence {
    mode = ${?PERSISTENCE_MODE}
    moduleClass = ${?PERSISTENCE_MODULE_CLASS}
    directoryPathSeparator = "/"
    directoryPathSeparator = ${?DIRECTORY_PATH_SEPARATOR}
    csvColumnSeparator = "\t"
    csvColumnSeparator = ${?CSV_COLUMN_SEPARATOR}
    local {
        dir = ${?LOCAL_STORAGE_DIR}
    }
  }
  writer {
    type = "local"
    dirpath = "/tmp/kolibri-testpath"
  }
  internal {
    jobStatusRequestTimeoutInSeconds = 3
    analyzeTimeoutInSeconds = 30
  }
  ssl {
    useInsecureEngine = false
    useInsecureEngine = ${?USE_INSECURE_SSL_ENGINE}
  }
}

#custom dispatcher
kolibri-dispatcher {
  # Dispatcher is the name of the event-based dispatcher
  type = Dispatcher
  # What kind of ExecutionService to use
  executor = "fork-join-executor"
  # Configuration for the fork join pool
  fork-join-executor {
    # Min number of threads to cap factor-based parallelism number to
    parallelism-min = 2
    # Parallelism (threads) ... ceil(available processors * factor)
    parallelism-factor = 2.00
    # Max number of threads to cap factor-based parallelism number to
    parallelism-max = 16
  }
  # Throughput defines the maximum number of messages to be
  # processed per actor before the thread jumps to the next actor.
  # Set to 1 for as fair as possible.
  throughput = 1
}

# overrides for akka-kryo-serialization lib (reference: https://github.com/altoo-ag/akka-kryo-serialization/blob/master/akka-kryo-serialization/src/main/resources/reference.conf)
akka-kryo-serialization {

    # max-buffer-size = 2147483639
    max-buffer-size = -1
    buffer-size = 4096
    post-serialization-transformations = "lz4"
    # kryo-reference-map = true

}

akka {
  log-config-on-start = false

  cluster.downing-provider-class = "akka.cluster.sbr.SplitBrainResolverProvider"

  actor {
    #provider = "akka.actor.LocalActorRefProvider"
    #either use cluster mode with one node also for local, or exclude the akka
    #node discovery libraries (management-cluster-bootstrap, akka-discovery-*) from build, since they require respective cluster discovery settings here
    provider = "cluster"
    # https://doc.akka.io/docs/akka/current/serialization.html
    serializers {
          # https://doc.akka.io/docs/akka/current/serialization-jackson.html
          jackson-json = "akka.serialization.jackson.JacksonJsonSerializer"
          jackson-cbor = "akka.serialization.jackson.JacksonCborSerializer"
          proto = "akka.remote.serialization.ProtobufSerializer"
          # https://github.com/altoo-ag/akka-kryo-serialization
          kryo = "io.altoo.akka.serialization.kryo.KryoSerializer"
        }
    serialization-bindings {
        "com.google.protobuf.Message" = proto
        "de.awagen.kolibri.datatypes.io.KolibriSerializable" = kryo
    }
    allow-java-serialization = off
    default-dispatcher {
        type = Dispatcher
        executor = "fork-join-executor"
        fork-join-executor {
         parallelism-factor: 1.00,
         parallelism-max: 2,
         parallelism-min: 1
       }
    }
  }


  remote {
    log-remote-lifecycle-events = off
    enabled-transports = ["akka.remote.netty.tcp"]
    maximum-payload-bytes = 30000000 bytes # related to the OversizedPayloadException described below in the netty.tcp section
    netty.tcp {
      hostname = "127.0.0.1"
      port = 0
      # allowing larger payload (otherwise larger messages (e.g aggregations) wont get through, resulting in messages like:
      # akka.remote.OversizedPayloadException: Discarding oversized payload sent to Actor[akka.tcp://KolibriAppSystem@172.33.1.1:40775/user/$b/solrExperimentManager-id1#-922313015]: max allowed size 128000 bytes, actual size of encoded class de.awagen.kolibri.searchopt.actors.work.serviceworker.MetricsAggregationWorker$ResultsProvidedEvent was 645757 bytes.
      message-frame-size =  30000000b
      send-buffer-size =  30000000b
      receive-buffer-size =  30000000b
      maximum-frame-size = 30000000b
    }
  }
}

#connection pool settings
akka.http.host-connection-pool {
  max-connections = 200
  min-connections = 0
  max-retries = 3
  max-open-requests = 512
  pipelining-limit = 1
  idle-timeout = 30 s
  pool-implementation = new
  response-entity-subscription-timeout = 3.second
}

#we need to set a basic akka.discovery.method since the respective dependencies require that
#alternatively, could use some hack around that, e.g : https://github.com/akka/akka-management/issues/166
akka.discovery {
  method = config

  config {
    class = "akka.discovery.config.ConfigServiceDiscovery"

    # Location of the services
    services-path = "akka.discovery.config.services"

    services {
      kolibri-service {
        endpoints = [
          {
            host = "127.0.0.1"
          }
        ]
      }
    }
  }
}

#setting also needed when discovery is active
akka.http.routing.decode-max-size = 8m
#needed to avoid message, e.g when starting two ActorSystems:
#Could not register Cluster JMX MBean with name=akka:type=Cluster as it is already registered. If you are running multiple clusters in the same JVM, set 'akka.cluster.jmx.multi-mbeans-in-same-jvm = on' in config
akka.cluster.jmx.multi-mbeans-in-same-jvm = on

#singleton routing actor
akka.actor.deployment {
  #see ClusterNode for creation of singleton creation with ClusterSingletonManager
  #singleton holds as soon as actor is created as singleton, routingActor is name of the respective actor and poolRouter the respective router created in the respective actor
  /singleton/routingActor/poolRouter {
    router = cluster-metrics-adaptive-pool
    metrics-selector = load
    #nr-of-instances = 100
    cluster {
      enabled = on
      max-nr-of-instances-per-node = 5
      allow-local-routees = on
      use-roles = ["compute"]
    }
  }

  /poolRouter {
        router = cluster-metrics-adaptive-pool
        metrics-selector = load
        # without defining the nr-of-instances and setting the max-nr-of-instances-per-node too high
        # can in high load situations cause non-routing of sent message, thus set reasonable values
        # TODO: haha no this was accidental since both max-nr and nr-of-instances had the same number and all
        # where placed on a single node , which was same as the one where jobmanager locates
        # nr-of-instances = 20
        cluster {
          enabled = on
          max-nr-of-instances-per-node = 10
          allow-local-routees = on
          use-roles = ["compute"]
        }
        pool-dispatcher {
          fork-join-executor.parallelism-min = 5
          fork-join-executor.parallelism-max = 20
        }
  }
}

akka.extensions = [ "akka.cluster.metrics.ClusterMetricsExtension" ]

#just got one node, so use both roles
akka.cluster.roles = ["compute", "httpserver"]

# akka management config for node discovery / cluster forming
include "discovery/akka-management.conf"
# singleton manager config for cluster singleton creation
include "cluster_singleton/k-akka-singleton-manager.conf"
# kamon config
include "metrics/kamon.conf"
