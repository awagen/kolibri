kolibri {
  actor-system = ${?KOLIBRI_ACTOR_SYSTEM_NAME}
  request {
    parallelism = 64
    useTracking = false
  }
  job {
   timeoutInSeconds = 1800
   processingCheckResourcesIntervalInMillis = 100
   runningTasksBaselineCount = 10
   batchDistributionIntervalInMs = 1000
   batchMaxTimeToACKInMs = 100
   resources {
   }
   tasks {
     waitForSynchronousTaskCompleteInMs = 100
   }
  }
  cluster {
    statusCheckTimeoutInMillis = 1000
    startClusterSingletonRouter = false
  }
  supervisor {
    maxNumOfRetries = 3
    maxNumOfRetriesWithinTimeInSeconds = 60
    houseKeepingIntervalInSeconds = 10
  }
  execution {
      runnableExecutionHouseKeepingIntervalInSeconds = 10
      jobManagerCheckForCompletionIntervalInSeconds = 5
  }
  format {
    metricDocumentFormatType = "parameter"
  }
  writer {
    type = "aws-s3"
    bucket = "testbucket"
    dirpath = "testpath"
    region = "EU_CENTRAL_1"
  }
  internal {
    jobStatusRequestTimeoutInSeconds = 3
  }
}

#custom dispatcher
kolibri-dispatcher {
  # Dispatcher is the name of the event-based dispatcher
  type = Dispatcher
  # What kind of ExecutionService to use
  executor = "fork-join-executor"
  # Configuration for the fork join pool
  fork-join-executor {
    # Min number of threads to cap factor-based parallelism number to
    parallelism-min = 2
    # Parallelism (threads) ... ceil(available processors * factor)
    parallelism-factor = 2.0
    # Max number of threads to cap factor-based parallelism number to
    parallelism-max = 8
  }
  # Throughput defines the maximum number of messages to be
  # processed per actor before the thread jumps to the next actor.
  # Set to 1 for as fair as possible.
  throughput = 10
}

akka {
  # Put the following in your conf/logback.xml file:
  # <logger name="akka.actor" level="INFO" />
  # And then set the log-config-on-start value to true to debug the configuration.
  log-config-on-start = false

  cluster.downing-provider-class = "akka.cluster.sbr.SplitBrainResolverProvider"

  actor {
    provider = "cluster"
    # https://doc.akka.io/docs/akka/current/serialization.html
    serializers {
      # https://doc.akka.io/docs/akka/current/serialization-jackson.html
      jackson-json = "akka.serialization.jackson.JacksonJsonSerializer"
      jackson-cbor = "akka.serialization.jackson.JacksonCborSerializer"
      proto = "akka.remote.serialization.ProtobufSerializer"
      # https://github.com/altoo-ag/akka-kryo-serialization
      kryo = "io.altoo.akka.serialization.kryo.KryoSerializer"
    }
    serialization-bindings {
      "com.google.protobuf.Message" = proto
      "de.awagen.kolibri.datatypes.io.KolibriSerializable" = kryo
    }
    allow-java-serialization = off
  }

  remote {
    log-remote-lifecycle-events = off
    enabled-transports = ["akka.remote.netty.tcp"]
    maximum-payload-bytes = 30000000 bytes # related to the OversizedPayloadException described below in the netty.tcp section
    netty.tcp {
      port = ${?CLUSTER_NODE_PORT}
      # allowing larger payload (otherwise larger messages (e.g aggregations) wont get through, resulting in messages like:
      # akka.remote.OversizedPayloadException: Discarding oversized payload sent to Actor[akka.tcp://KolibriAppSystem@172.33.1.1:40775/user/$b/solrExperimentManager-id1#-922313015]: max allowed size 128000 bytes, actual size of encoded class de.awagen.kolibri.searchopt.actors.work.serviceworker.MetricsAggregationWorker$ResultsProvidedEvent was 645757 bytes.
      message-frame-size =  30000000b
      send-buffer-size =  30000000b
      receive-buffer-size =  30000000b
      maximum-frame-size = 30000000b
    }
  }

  cluster {
    # defines role for the node using this config
    roles = ["httpserver", "compute"]
  }
}

#cluster-aware router
#detailed description of routing: https://doc.akka.io/docs/akka/current/routing.html?language=scala
#can define a Resizer in pool which automatically adjusts the number of instances (check if that works with
# router cluster-metrics-adaptive-group)
akka.actor.deployment {
  #see ClusterNode for creation of singleton creation with ClusterSingletonManager
  #singleton holds as soon as actor is created as singleton, routingActor is name of the respective actor and poolRouter the respective router created in the respective actor
  /singleton/routingActor/poolRouter {
    router = cluster-metrics-adaptive-pool
    metrics-selector = load
    # without defining the nr-of-instances and setting the max-nr-of-instances-per-node too high
    # can in high load situations cause non-routing of sent message, thus set reasonable values
    # TODO: haha no this was accidental since both max-nr and nr-of-instances had the same number and all
    # where placed on a single node , which was same as the one where jobmanager locates
    # nr-of-instances = 20
    cluster {
      enabled = on
      max-nr-of-instances-per-node = 10
      allow-local-routees = on
      use-roles = ["compute"]
    }
    pool-dispatcher {
      fork-join-executor.parallelism-min = 5
      fork-join-executor.parallelism-max = 20
    }
  }

  /poolRouter {
      router = cluster-metrics-adaptive-pool
      metrics-selector = load
      # without defining the nr-of-instances and setting the max-nr-of-instances-per-node too high
      # can in high load situations cause non-routing of sent message, thus set reasonable values
      # TODO: haha no this was accidental since both max-nr and nr-of-instances had the same number and all
      # where placed on a single node , which was same as the one where jobmanager locates
      # nr-of-instances = 20
      cluster {
        enabled = on
        max-nr-of-instances-per-node = 10
        allow-local-routees = on
        use-roles = ["compute"]
      }
      pool-dispatcher {
        fork-join-executor.parallelism-min = 5
        fork-join-executor.parallelism-max = 20
      }
    }
}

akka.extensions = [ "akka.cluster.metrics.ClusterMetricsExtension" ]

//added to ensure heartbeats (gossip protocol) are sent even if system under load
akka.cluster.use-dispatcher = cluster-dispatcher
cluster-dispatcher {
  type = "Dispatcher"
  executor = "fork-join-executor"
  fork-join-executor {
    parallelism-min = 2
    parallelism-max = 4
  }
}


#connection pool settings
akka.http.host-connection-pool {
  # The maximum number of parallel connections that a connection pool to a
  # single host endpoint is allowed to establish. Must be greater than zero.
  max-connections = 50

  # The minimum number of parallel connections that a pool should keep alive ("hot").
  # If the number of connections is falling below the given threshold, new ones are being spawned.
  # You can use this setting to build a hot pool of "always on" connections.
  # Default is 0, meaning there might be no active connection at given moment.
  # Keep in mind that `min-connections` should be smaller than `max-connections` or equal
  min-connections = 0

  # The maximum number of times failed requests are attempted again,
  # (if the request can be safely retried) before giving up and returning an error.
  # Set to zero to completely disable request retries.
  max-retries = 3

  # The maximum number of open requests accepted into the pool across all
  # materializations of any of its client flows.
  # Protects against (accidentally) overloading a single pool with too many client flow materializations.
  # Note that with N concurrent materializations the max number of open request in the pool
  # will never exceed N * max-connections * pipelining-limit.
  # Must be a power of 2 and > 0!
  max-open-requests = 512  #set quite high since its just a safeguard against too many connection pool flow materializations

  # The maximum number of requests that are dispatched to the target host in
  # batch-mode across a single connection (HTTP pipelining).
  # A setting of 1 disables HTTP pipelining, since only one request per
  # connection can be "in flight" at any time.
  # Set to higher values to enable HTTP pipelining.
  # This value must be > 0.
  # (Note that, independently of this setting, pipelining will never be done
  # on a connection that still has a non-idempotent request in flight.
  #
  # Before increasing this value, make sure you understand the effects of head-of-line blocking.
  # Using a connection pool, a request may be issued on a connection where a previous
  # long-running request hasn't finished yet. The response to the pipelined requests may then be stuck
  # behind the response of the long-running previous requests on the server. This may introduce an
  # unwanted "coupling" of run time between otherwise unrelated requests.
  #
  # See http://tools.ietf.org/html/rfc7230#section-6.3.2 for more info.)
  pipelining-limit = 1

  # The time after which an idle connection pool (without pending requests)
  # will automatically terminate itself. Set to `infinite` to completely disable idle timeouts.
  idle-timeout = 30 s

  # The pool implementation to use. Currently supported are:
  #  - legacy: the original 10.0.x pool implementation
  #  - new: the pool implementation that became the default in 10.1.x and will receive fixes and new features
  pool-implementation = new

  # The "new" pool implementation will fail a connection early and clear the slot if a response entity was not
  # subscribed during the given time period after the response was dispatched. In busy systems the timeout might be
  # too tight if a response is not picked up quick enough after it was dispatched by the pool.
  response-entity-subscription-timeout = 3.second
  #response-entity-subscription-timeout = 500.millis
}

akka.http.client {
  # The time period within which the TCP connecting process must be completed.
  connection-timeout = 3s

  # The time after which an idle connection will be automatically closed.
  # Set to `infinite` to completely disable idle timeouts.
  idle-timeout = 5s
}

#akka routing settings (akka-http section in : https://doc.akka.io/docs/akka-http/current/configuration.html)
akka.http.routing {
  # Maximum content length after applying a decoding directive.
  decode-max-size = 8m

  # Fully qualified config path which holds the dispatcher configuration
  # to be used by FlowMaterialiser when creating Actors for IO operations.
  file-io-dispatcher = ${akka.stream.blocking-io-dispatcher}
}

akka.cluster.shutdown-after-unsuccessful-join-seed-nodes = 60s

#If you are running multiple clusters in the same JVM, set this 'on'
akka.cluster.jmx.multi-mbeans-in-same-jvm = on

#only logs first number of dead letters (not in total, per case)
akka.log-dead-letters = 10
akka.log-dead-letters-during-shutdown = off

#need to create logger with "val log = Logging(system.eventStream, "my.nice.string") or other constructor"
akka {
  loggers = ["akka.event.slf4j.Slf4jLogger"]
  loglevel = "DEBUG"
  logging-filter = "akka.event.slf4j.Slf4jLoggingFilter"
}